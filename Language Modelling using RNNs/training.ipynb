{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "oxiZ42B4SwQ-"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tests import test_prediction, test_generation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Nov 22 14:28:17 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.33.01    Driver Version: 440.33.01    CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  TITAN RTX           Off  | 00000000:04:00.0 Off |                  N/A |\n",
      "| 42%   63C    P2   182W / 280W |  21757MiB / 24220MiB |     92%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  TITAN RTX           Off  | 00000000:05:00.0 Off |                  N/A |\n",
      "| 82%   87C    P2   174W / 280W |  19108MiB / 24220MiB |     85%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  TITAN RTX           Off  | 00000000:08:00.0 Off |                  N/A |\n",
      "| 96%   88C    P2   107W / 280W |  19108MiB / 24220MiB |     84%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  TITAN RTX           Off  | 00000000:09:00.0 Off |                  N/A |\n",
      "| 91%   88C    P2   135W / 280W |  19108MiB / 24220MiB |     85%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  TITAN RTX           Off  | 00000000:84:00.0 Off |                  N/A |\n",
      "| 41%   38C    P8     3W / 280W |  21178MiB / 24220MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  TITAN RTX           Off  | 00000000:85:00.0 Off |                  N/A |\n",
      "| 70%   86C    P2   246W / 280W |  24014MiB / 24220MiB |     86%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  TITAN RTX           Off  | 00000000:88:00.0 Off |                  N/A |\n",
      "| 41%   33C    P8    19W / 280W |   2526MiB / 24220MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  TITAN RTX           Off  | 00000000:89:00.0 Off |                  N/A |\n",
      "| 68%   86C    P2   148W / 280W |  24014MiB / 24220MiB |     40%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0      7300      C   python                                     20865MiB |\n",
      "|    0     32208      C   .../anaconda3/envs/shayeree_env/bin/python   861MiB |\n",
      "|    1      7300      C   python                                     19077MiB |\n",
      "|    2      7300      C   python                                     19077MiB |\n",
      "|    3      7300      C   python                                     19077MiB |\n",
      "|    4     32208      C   .../anaconda3/envs/shayeree_env/bin/python 21167MiB |\n",
      "|    5     43963      C   python3                                    24003MiB |\n",
      "|    7     14462      C   python3                                    24003MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kill 19671  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "x5znxQhLSwRC"
   },
   "outputs": [],
   "source": [
    "# load all that we need\n",
    "dataset = np.load('../dataset/wiki.train.npy', allow_pickle=True)\n",
    "devset = np.load('../dataset/wiki.valid.npy', allow_pickle=True)\n",
    "fixtures_pred = np.load('../fixtures/prediction.npz')  # dev\n",
    "fixtures_gen = np.load('../fixtures/generation.npy')  # dev\n",
    "fixtures_pred_test = np.load('../fixtures/prediction_test.npz')  # test\n",
    "fixtures_gen_test = np.load('../fixtures/generation_test.npy')  # test\n",
    "vocab = np.load('../dataset/vocab.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3803,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "devset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33278,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device(\"cuda:6\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "OZNrJ8XvSwRF"
   },
   "outputs": [],
   "source": [
    "# data loader\n",
    "\n",
    "class LanguageModelDataLoader(DataLoader):\n",
    "    \"\"\"\n",
    "        TODO: Define data loader logic here\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset, batch_size, shuffle=True):\n",
    "        \n",
    "        self.dataset=dataset\n",
    "        self.bs=batch_size\n",
    "        self.shuffle=shuffle\n",
    "\n",
    "    def __iter__(self):\n",
    "        \n",
    "        # concatenate your articles and build into batches\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.dataset)\n",
    "        #In order to concatenate we must flatten\n",
    "        concat=np.concatenate(self.dataset)\n",
    "        \n",
    "        #print(\"Shape of dataset :\",self.dataset.shape)\n",
    "        #now we have to choose the sequence length\n",
    "        #We use BPTT as used in the paper\n",
    "        \n",
    "        #Now we have the seq_len\n",
    "        #Now we can group the articles into sequences based on the batch size\n",
    "        no_of_splits=(concat.shape[0]-1)//self.bs\n",
    "        X=torch.from_numpy(concat[:no_of_splits*self.bs].reshape(self.bs,-1)).type(torch.LongTensor)\n",
    "        Y=torch.from_numpy(concat[1:no_of_splits*self.bs+1].reshape(self.bs,-1)).type(torch.LongTensor)\n",
    "        idx=0\n",
    "        #print(\"No of possible splits :\", no_of_splits)\n",
    "        while idx < no_of_splits:\n",
    "            p=np.random.random_sample()\n",
    "            if p < 0.95:\n",
    "                seq_len=round(np.random.normal(70,5))\n",
    "            else:\n",
    "                seq_len=round(np.random.normal(35,5))\n",
    "            final_X=X[:,idx:idx+seq_len]\n",
    "            final_Y=Y[:,idx:idx+seq_len]\n",
    "            idx=idx+seq_len\n",
    "            yield final_X, final_Y\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "Zt-7YsTYSwRI"
   },
   "outputs": [],
   "source": [
    "# model\n",
    "class LanguageModel(nn.Module):\n",
    "    \"\"\"\n",
    "        TODO: Define your model here\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size):\n",
    "        super(LanguageModel, self).__init__()\n",
    "        \n",
    "        #Embedding Layer\n",
    "        #LSTM Layer\n",
    "        self.embed=nn.Embedding(vocab_size,400)\n",
    "        self.lstm = nn.LSTM(400,hidden_size=1150,num_layers=3,batch_first=True)\n",
    "        self.linear = nn.Linear(1150, vocab_size)\n",
    "\n",
    "    def forward(self, x,h0=None):\n",
    "        # Feel free to add extra arguments to forward (like an argument to pass in the hiddens)\n",
    "        x=self.embed(x)\n",
    "        if h0:\n",
    "            x, hidden = self.lstm(x, h0)\n",
    "        else:\n",
    "            x, hidden = self.lstm(x)\n",
    "        self.lstm.flatten_parameters()\n",
    "        x=self.linear(x)\n",
    "\n",
    "        return x,hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "kIvZOIfjSwRK"
   },
   "outputs": [],
   "source": [
    "# model trainer\n",
    "\n",
    "class LanguageModelTrainer:\n",
    "    def __init__(self, model, loader, max_epochs=1, run_id='exp'):\n",
    "        \"\"\"\n",
    "            Use this class to train your model\n",
    "        \"\"\"\n",
    "        # feel free to add any other parameters here\n",
    "        self.model = model\n",
    "        self.loader = loader\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.predictions = []\n",
    "        self.predictions_test = []\n",
    "        self.generated_logits = []\n",
    "        self.generated = []\n",
    "        self.generated_logits_test = []\n",
    "        self.generated_test = []\n",
    "        self.epochs = 0\n",
    "        self.max_epochs = max_epochs\n",
    "        self.run_id = run_id\n",
    "        \n",
    "        # TODO: Define your optimizer and criterion here\n",
    "        self.optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-6)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def train(self):\n",
    "        self.model.train() # set to training mode\n",
    "        epoch_loss = 0\n",
    "        num_batches = 0\n",
    "        for batch_num, (inputs, targets) in enumerate(self.loader):\n",
    "            epoch_loss += self.train_batch(inputs, targets)\n",
    "        epoch_loss = epoch_loss / (batch_num + 1)\n",
    "        self.epochs += 1\n",
    "        print('[TRAIN]  Epoch [%d/%d]   Loss: %.4f'\n",
    "                      % (self.epochs + 1, self.max_epochs, epoch_loss))\n",
    "        self.train_losses.append(epoch_loss)\n",
    "\n",
    "    def train_batch(self, inputs, targets):\n",
    "        \"\"\" \n",
    "            TODO: Define code for training a single batch of inputs\n",
    "        \n",
    "        \"\"\"\n",
    "        inputs=inputs.to(device)\n",
    "        targets=targets.to(device)\n",
    "        output,_=self.model(inputs)\n",
    "        loss=self.criterion(output.view(-1, output.size(2)),targets.view(-1))\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        del inputs\n",
    "        del targets\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def test(self):\n",
    "        # don't change these\n",
    "        self.model.eval() # set to eval mode\n",
    "        predictions = TestLanguageModel.prediction(fixtures_pred['inp'], self.model) # get predictions\n",
    "        self.predictions.append(predictions)\n",
    "        generated_logits = TestLanguageModel.generation(fixtures_gen, 10, self.model) # generated predictions for 10 words\n",
    "        generated_logits_test = TestLanguageModel.generation(fixtures_gen_test, 10, self.model)\n",
    "        nll = test_prediction(predictions, fixtures_pred['out'])\n",
    "        generated = test_generation(fixtures_gen, generated_logits, vocab)\n",
    "        generated_test = test_generation(fixtures_gen_test, generated_logits_test, vocab)\n",
    "        self.val_losses.append(nll)\n",
    "        \n",
    "        self.generated.append(generated)\n",
    "        self.generated_test.append(generated_test)\n",
    "        self.generated_logits.append(generated_logits)\n",
    "        self.generated_logits_test.append(generated_logits_test)\n",
    "        \n",
    "        # generate predictions for test data\n",
    "        predictions_test = TestLanguageModel.prediction(fixtures_pred_test['inp'], self.model) # get predictions\n",
    "        self.predictions_test.append(predictions_test)\n",
    "            \n",
    "        print('[VAL]  Epoch [%d/%d]   Loss: %.4f'\n",
    "                      % (self.epochs + 1, self.max_epochs, nll))\n",
    "        return nll\n",
    "\n",
    "    def save(self):\n",
    "        # don't change these\n",
    "        model_path = os.path.join('experiments', self.run_id, 'model-{}.pkl'.format(self.epochs))\n",
    "        torch.save({'state_dict': self.model.state_dict()},\n",
    "            model_path)\n",
    "        np.save(os.path.join('experiments', self.run_id, 'predictions-{}.npy'.format(self.epochs)), self.predictions[-1])\n",
    "        np.save(os.path.join('experiments', self.run_id, 'predictions-test-{}.npy'.format(self.epochs)), self.predictions_test[-1])\n",
    "        np.save(os.path.join('experiments', self.run_id, 'generated_logits-{}.npy'.format(self.epochs)), self.generated_logits[-1])\n",
    "        np.save(os.path.join('experiments', self.run_id, 'generated_logits-test-{}.npy'.format(self.epochs)), self.generated_logits_test[-1])\n",
    "        with open(os.path.join('experiments', self.run_id, 'generated-{}.txt'.format(self.epochs)), 'w') as fw:\n",
    "            fw.write(self.generated[-1])\n",
    "        with open(os.path.join('experiments', self.run_id, 'generated-{}-test.txt'.format(self.epochs)), 'w') as fw:\n",
    "            fw.write(self.generated_test[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "id": "xPI7_kZRSwRN"
   },
   "outputs": [],
   "source": [
    "class TestLanguageModel:\n",
    "    def prediction(inp, model):\n",
    "        \"\"\"\n",
    "            TODO: write prediction code here\n",
    "            \n",
    "            :param inp:\n",
    "            :return: a np.ndarray of logits\n",
    "        \"\"\"\n",
    "        output,_=model(torch.LongTensor(inp).to(device))\n",
    "        output=output[:,-1]#We only want the prob for the last word at the end of the sequence\n",
    "        \n",
    "        return output.cpu().detach().numpy()\n",
    "\n",
    "        \n",
    "    def generation(inp, forward, model):\n",
    "        \"\"\"\n",
    "            TODO: write generation code here\n",
    "\n",
    "            Generate a sequence of words given a starting sequence.\n",
    "            :param inp: Initial sequence of words (batch size, length)\n",
    "            :param forward: number of additional words to generate\n",
    "            :return: generated words (batch size, forward)\n",
    "            \n",
    "            \n",
    "        \"\"\" \n",
    "        model.eval()\n",
    "        generated_words=[]\n",
    "        #print(\"Shape of input:\",inp.shape)\n",
    "        output,hidden=model(torch.LongTensor(inp).to(device))\n",
    "        #print(\"output shape:\",output.shape)\n",
    "        current_word=torch.argmax(output,dim=2)#B,Seq_len,Vocab_size\n",
    "        #print(\"Current word shape :\",current_word.shape)##B,Seq_len,1\n",
    "        current_word=current_word[:,-1].unsqueeze(dim=1)#B,1,We need the last word only\n",
    "        #print(\"Current word shape :\",current_word.shape)\n",
    "        \n",
    "        generated_words.append(current_word)\n",
    "        if forward > 1:\n",
    "            for i in range(forward-1):\n",
    "                output,hidden=model(current_word,hidden)\n",
    "                current_word = torch.argmax(output,dim=2) # B,S,Vocab_size\n",
    "                current_word=current_word[:,-1].unsqueeze(dim=1)#B,1,We need the last word only,with argmx and concat that\n",
    "                generated_words.append(current_word)\n",
    "                \n",
    "        return torch.cat(generated_words,dim=1).cpu().detach().numpy()    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "TiUrjbEjSwRQ"
   },
   "outputs": [],
   "source": [
    "# TODO: define other hyperparameters here\n",
    "NUM_EPOCHS = 10\n",
    "BATCH_SIZE = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "2HCVG5YISwRW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving models, predictions, and generated words to ./experiments/1606081046\n"
     ]
    }
   ],
   "source": [
    "run_id = str(int(time.time()))\n",
    "if not os.path.exists('./experiments'):\n",
    "    os.mkdir('./experiments')\n",
    "os.mkdir('./experiments/%s' % run_id)\n",
    "print(\"Saving models, predictions, and generated words to ./experiments/%s\" % run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "DbHH6zXTSwRa"
   },
   "outputs": [],
   "source": [
    "model = LanguageModel(len(vocab))\n",
    "model.to(device)\n",
    "#model = nn.DataParallel(model,device_ids=[4,5,6]).to(device)\n",
    "loader = LanguageModelDataLoader(dataset=dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "trainer = LanguageModelTrainer(model=model, loader=loader, max_epochs=NUM_EPOCHS, run_id=run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "7D8wTJkBSwRc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [2/10]   Loss: 7.3301\n",
      "Shape of input: (32, 20)\n",
      "output shape: torch.Size([32, 20, 33278])\n",
      "Current word shape : torch.Size([32, 20])\n",
      "Current word shape : torch.Size([32, 1])\n",
      "Shape of input: (128, 30)\n",
      "output shape: torch.Size([128, 30, 33278])\n",
      "Current word shape : torch.Size([128, 30])\n",
      "Current word shape : torch.Size([128, 1])\n",
      "[VAL]  Epoch [2/10]   Loss: 6.4843\n",
      "Saving model, predictions and generated output for epoch 0 with NLL: 6.4842596\n",
      "[TRAIN]  Epoch [3/10]   Loss: 6.6802\n",
      "Shape of input: (32, 20)\n",
      "output shape: torch.Size([32, 20, 33278])\n",
      "Current word shape : torch.Size([32, 20])\n",
      "Current word shape : torch.Size([32, 1])\n",
      "Shape of input: (128, 30)\n",
      "output shape: torch.Size([128, 30, 33278])\n",
      "Current word shape : torch.Size([128, 30])\n",
      "Current word shape : torch.Size([128, 1])\n",
      "[VAL]  Epoch [3/10]   Loss: 5.7764\n",
      "Saving model, predictions and generated output for epoch 1 with NLL: 5.7764006\n",
      "[TRAIN]  Epoch [4/10]   Loss: 5.9800\n",
      "Shape of input: (32, 20)\n",
      "output shape: torch.Size([32, 20, 33278])\n",
      "Current word shape : torch.Size([32, 20])\n",
      "Current word shape : torch.Size([32, 1])\n",
      "Shape of input: (128, 30)\n",
      "output shape: torch.Size([128, 30, 33278])\n",
      "Current word shape : torch.Size([128, 30])\n",
      "Current word shape : torch.Size([128, 1])\n",
      "[VAL]  Epoch [4/10]   Loss: 5.2898\n",
      "Saving model, predictions and generated output for epoch 2 with NLL: 5.289776\n",
      "[TRAIN]  Epoch [5/10]   Loss: 5.5452\n",
      "Shape of input: (32, 20)\n",
      "output shape: torch.Size([32, 20, 33278])\n",
      "Current word shape : torch.Size([32, 20])\n",
      "Current word shape : torch.Size([32, 1])\n",
      "Shape of input: (128, 30)\n",
      "output shape: torch.Size([128, 30, 33278])\n",
      "Current word shape : torch.Size([128, 30])\n",
      "Current word shape : torch.Size([128, 1])\n",
      "[VAL]  Epoch [5/10]   Loss: 4.9575\n",
      "Saving model, predictions and generated output for epoch 3 with NLL: 4.95749\n",
      "[TRAIN]  Epoch [6/10]   Loss: 5.2670\n",
      "Shape of input: (32, 20)\n",
      "output shape: torch.Size([32, 20, 33278])\n",
      "Current word shape : torch.Size([32, 20])\n",
      "Current word shape : torch.Size([32, 1])\n",
      "Shape of input: (128, 30)\n",
      "output shape: torch.Size([128, 30, 33278])\n",
      "Current word shape : torch.Size([128, 30])\n",
      "Current word shape : torch.Size([128, 1])\n",
      "[VAL]  Epoch [6/10]   Loss: 4.7629\n",
      "Saving model, predictions and generated output for epoch 4 with NLL: 4.762946\n",
      "[TRAIN]  Epoch [7/10]   Loss: 5.0404\n",
      "Shape of input: (32, 20)\n",
      "output shape: torch.Size([32, 20, 33278])\n",
      "Current word shape : torch.Size([32, 20])\n",
      "Current word shape : torch.Size([32, 1])\n",
      "Shape of input: (128, 30)\n",
      "output shape: torch.Size([128, 30, 33278])\n",
      "Current word shape : torch.Size([128, 30])\n",
      "Current word shape : torch.Size([128, 1])\n",
      "[VAL]  Epoch [7/10]   Loss: 4.6718\n",
      "Saving model, predictions and generated output for epoch 5 with NLL: 4.6717777\n",
      "[TRAIN]  Epoch [8/10]   Loss: 4.8616\n",
      "Shape of input: (32, 20)\n",
      "output shape: torch.Size([32, 20, 33278])\n",
      "Current word shape : torch.Size([32, 20])\n",
      "Current word shape : torch.Size([32, 1])\n",
      "Shape of input: (128, 30)\n",
      "output shape: torch.Size([128, 30, 33278])\n",
      "Current word shape : torch.Size([128, 30])\n",
      "Current word shape : torch.Size([128, 1])\n",
      "[VAL]  Epoch [8/10]   Loss: 4.6007\n",
      "Saving model, predictions and generated output for epoch 6 with NLL: 4.6006546\n",
      "[TRAIN]  Epoch [9/10]   Loss: 4.6995\n",
      "Shape of input: (32, 20)\n",
      "output shape: torch.Size([32, 20, 33278])\n",
      "Current word shape : torch.Size([32, 20])\n",
      "Current word shape : torch.Size([32, 1])\n",
      "Shape of input: (128, 30)\n",
      "output shape: torch.Size([128, 30, 33278])\n",
      "Current word shape : torch.Size([128, 30])\n",
      "Current word shape : torch.Size([128, 1])\n",
      "[VAL]  Epoch [9/10]   Loss: 4.5107\n",
      "Saving model, predictions and generated output for epoch 7 with NLL: 4.5106697\n",
      "[TRAIN]  Epoch [10/10]   Loss: 4.5621\n",
      "Shape of input: (32, 20)\n",
      "output shape: torch.Size([32, 20, 33278])\n",
      "Current word shape : torch.Size([32, 20])\n",
      "Current word shape : torch.Size([32, 1])\n",
      "Shape of input: (128, 30)\n",
      "output shape: torch.Size([128, 30, 33278])\n",
      "Current word shape : torch.Size([128, 30])\n",
      "Current word shape : torch.Size([128, 1])\n",
      "[VAL]  Epoch [10/10]   Loss: 4.5615\n",
      "[TRAIN]  Epoch [11/10]   Loss: 4.4341\n",
      "Shape of input: (32, 20)\n",
      "output shape: torch.Size([32, 20, 33278])\n",
      "Current word shape : torch.Size([32, 20])\n",
      "Current word shape : torch.Size([32, 1])\n",
      "Shape of input: (128, 30)\n",
      "output shape: torch.Size([128, 30, 33278])\n",
      "Current word shape : torch.Size([128, 30])\n",
      "Current word shape : torch.Size([128, 1])\n",
      "[VAL]  Epoch [11/10]   Loss: 4.4432\n",
      "Saving model, predictions and generated output for epoch 9 with NLL: 4.4432\n"
     ]
    }
   ],
   "source": [
    "best_nll = 1e30 \n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    trainer.train()\n",
    "    nll = trainer.test()\n",
    "    if nll < best_nll:\n",
    "        best_nll = nll\n",
    "        print(\"Saving model, predictions and generated output for epoch \"+str(epoch)+\" with NLL: \"+ str(best_nll))\n",
    "        trainer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "z2FmDqBCSwRf"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Don't change these\n",
    "# plot training curves\n",
    "plt.figure()\n",
    "plt.plot(range(1, trainer.epochs + 1), trainer.train_losses, label='Training losses')\n",
    "plt.plot(range(1, trainer.epochs + 1), trainer.val_losses, label='Validation losses')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('NLL')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "ipdbmqaGSwRh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input | Output #0: while the group was en route , but only three were ultimately able to attack . None of them were | not able to take the ball to the ground ,\n",
      "Input | Output #1: <unk> , where he remained on loan until 30 June 2010 . <eol> = = = Return to Manchester United | = = = <eol> The first two @-@ year contract\n",
      "Input | Output #2: 25 April 2013 , denoting shipments of 500 @,@ 000 copies . <eol> The song became One Direction 's fourth | single , \" The <unk> \" , which was released\n",
      "Input | Output #3: , and Bruce R. ) one daughter ( Wendy J. <unk> ) and two grandchildren , died in <unk> , | and <unk> . <eol> = = = <unk> = =\n",
      "Input | Output #4: Warrior were examples of this type . Because their armor was so heavy , they could only carry a single | @-@ scale <unk> , and the <unk> of the <unk>\n",
      "Input | Output #5: the embassy at 1 : 49 and landed on Guam at 2 : 23 ; twenty minutes later , Ambassador | and <unk> were sent to the <unk> . <eol> =\n",
      "Input | Output #6: <unk> , $ 96 million USD ) . Damage was heaviest in South Korea , notably where it moved ashore | . The storm moved into the Pacific Ocean on October\n",
      "Input | Output #7: The <unk> were condemned as <unk> by <unk> , who saw the riots as hampering attempts to resolve the situation | . <eol> = = = <unk> = = = <eol>\n",
      "Input | Output #8: by a decision made by the War Office in mid @-@ 1941 , as it was considering the equipment to | be the first of the city . The first of\n",
      "Input | Output #9: Division crossed the <unk> at a number of places and climbed the hills quietly toward the 9th Infantry river line | . The first ANZAC ships were also the only battalion\n",
      "Input | Output #10: = <eol> = = = French VIII . Corps ( Corps <unk> ) = = = <eol> On 6 November | , the Ustaše was sent to the United States Navy\n",
      "Input | Output #11: of the World from 9th Avenue \" . This is regarded as his most famous work . It is considered | a \" <unk> \" , and the \" <unk> of\n",
      "Input | Output #12: — <unk> @-@ 10 , <unk> @-@ 12 , <unk> @-@ 16 , <unk> @-@ 17 — were all converted | into the <unk> . <eol> = = = <unk> =\n",
      "Input | Output #13: And now he has . \" <eol> = = Family = = <eol> <unk> lived 37 of his years in | the United States . <eol> = = = <unk> =\n",
      "Input | Output #14: Hell to which he has been condemned for <unk> . Eliot , in a letter to John <unk> dated 27 | June , was a member of the <unk> of the\n",
      "Input | Output #15: Luoyang area , fulfilling his duties in domestic affairs . <eol> In the autumn of <unk> , he met Li | <unk> , who had been the first governor of the\n",
      "Input | Output #16: Power said they enjoyed Block Ball and its number of stages , but wondered how its eight <unk> of memory | was not <unk> . <eol> = = = <unk> =\n",
      "Input | Output #17: by Lloyd F. Lonergan . The cameraman was Jacques <unk> . <eol> = = Release and reception = = <eol> | The episode was written by the <unk> of the <unk>\n",
      "Input | Output #18: alone , the Austrians lost more than half their reserve artillery park , 6 @,@ 000 ( out of 8 | @,@ 000 ) , and the first of the two\n",
      "Input | Output #19: while attacking a ship at <unk> in the Dutch East Indies ; the loss was compounded by the fact that | the NDH had been <unk> by the British Empire .\n",
      "Input | Output #20: first raised in 2007 by the member of parliament ( MP ) for <unk> . The gangsters may have run | the <unk> of the <unk> and <unk> of the <unk>\n",
      "Input | Output #21: Species are also non @-@ spiny <unk> and includes both large trees with stout stems up to 30 metres ( | 1 @.@ 8 in ) thick . The oribi is\n",
      "Input | Output #22: \" : specific design issues with the building 's energy efficiency included the fact that the largest room in the | city was the first of the city 's main population\n",
      "Input | Output #23: were reported to support over 300 @,@ 000 households in the Brazilian state of <unk> in 2005 , and in | the United States , the first of the city 's\n",
      "Input | Output #24: port . <unk> in Vietnam also warned for the potential of heavy rainfall due to the dissipating Tropical Depression <unk> | . <eol> = = = Tropical Storm Eighteen = =\n",
      "Input | Output #25: T @-@ numbers in their tropical cyclone products . The following example is from discussion number 3 of Tropical Depression | Twenty @-@ E in the United States . <eol> =\n",
      "Input | Output #26: South Australia hosted the three @-@ game semi @-@ final series against the New South Wales <unk> . Both teams | were also the first team in the season . <eol>\n",
      "Input | Output #27: Perth from contention and secured the last finals spot for the <unk> . <eol> = = = Statistical leaders = | = = <eol> The first two @-@ year @-@ old\n",
      "Input | Output #28: deemed it an \" amazing pop song \" , lauding the group 's falsetto and its \" head @-@ <unk> | \" . The song was released on the Billboard Hot\n",
      "Input | Output #29: , but began patrolling the English Channel after <unk> @-@ 6 pioneered a route past British <unk> nets and mines | . The company was also the first of the British\n",
      "Input | Output #30: production executives to let him direct . He had already discussed the film with <unk> and Cohen , and felt | that the episode was \" <unk> \" . <eol> =\n",
      "Input | Output #31: and Nick <unk> at Studio <unk> in Los Angeles , California , and was released on August 1 , 2006 | . <eol> = = = <unk> = = = <eol>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# see generated output\n",
    "print (trainer.generated[-1]) # get last generated output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: Syntax error: end of file unexpected\r\n"
     ]
    }
   ],
   "source": [
    "!make runid=<experiments/1606081046/> epoch=<10>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
